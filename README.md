# Face-Human-Bench: A Comprehensive Face and Human Understanding Benchmark for Large Visual Language Models

<p align="center">
    <img src="https://github.com/Face-Human-Bench/face-human-bench/blob/main/pictures/logo.png" width="30%"> <br>
</p>


## Introduction

In recent years, Large Vision-Language Models have made significant advancements, demonstrating robust perception and reasoning capabilities concerning visual information. We would like to know whether LVLMs have a sufficient understanding of faces and human bodies. To this end, we have developed the Face-Human-Bench, which encompasses evaluations across ten distinct capabilities: Facial Attribute Recognition, Age Estimation, Facial Expression Recognition, Face Attack Detection, Face Recognition, Human Attribute Recognition, Action Recognition, Spatial Relation Understanding, Social Relation Understanding, and Person Re-Identification. Some of these capabilities can be further subdivided into multiple sub-capabilities, as illustrated in the figure below.

 <img src="https://github.com/Face-Human-Bench/face-human-bench/blob/main/pictures/main.png" alt="Image" width="800">


## ðŸ’¥ News
- **[2024.7.28]** Our project homepage can be accessed at https://face-human-bench.github.io.

## Scores
The scores of the partial model on 10 capabilitiesï¼š

<img src="https://github.com/Face-Human-Bench/face-human-bench/blob/main/pictures/ability.jpg" alt="Image" width="500">

The scores of the partial model on sub-capabilities for face understandingï¼š

<img src="https://github.com/Face-Human-Bench/face-human-bench/blob/main/pictures/face.jpg" alt="Image" width="500">

The scores of the partial model on sub-capabilities for human understandingï¼š

<img src="https://github.com/Face-Human-Bench/face-human-bench/blob/main/pictures/human.jpg" alt="Image" width="500">

## Citation

If you find **Face-Human-Bench** useful for your research and applications, please kindly cite using this BibTeX:

```latex
@misc{2024face-human-bench,
    title={Face-Human-Bench: A Comprehensive Face and Human Understanding Benchmark for Large Visual Language Models},
    author={*Qin, Lixiong and *Ou, Shilong and Liu, Yuchen and Song, Xiaoshuai and Ma, Changlian and Xu, Weiran},
    publisher = {GitHub},
    howpublished= "https://github.com/Face-Human-Bench/face-human-bench/",
    year={2024}
}
```


## Contributors

Here are the key contributors to this project:

Lixiong Qin*, Shilong Ou*, Yuchen Liu, Xiaoshuai Song, Changlian Ma, Weiran Xu
\* Equal contribution

[PRIS-NLP Research Group](https://pris-nlp.github.io/) , Beijing University of Posts and Telecommunications.
